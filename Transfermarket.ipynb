{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f3a29ab",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Getting-and-Cleaning-the-Data\" data-toc-modified-id=\"Getting-and-Cleaning-the-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Getting and Cleaning the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Webscraping-data-from-Transfermarkt.ch\" data-toc-modified-id=\"Webscraping-data-from-Transfermarkt.ch-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Webscraping data from Transfermarkt.ch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Aggregate-Transfer-Data-(League-/-Country-Level)\" data-toc-modified-id=\"Aggregate-Transfer-Data-(League-/-Country-Level)-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Aggregate Transfer Data (League / Country Level)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Web-Scraping\" data-toc-modified-id=\"Web-Scraping-2.1.1.1\"><span class=\"toc-item-num\">2.1.1.1&nbsp;&nbsp;</span>Web-Scraping</a></span></li><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-2.1.1.2\"><span class=\"toc-item-num\">2.1.1.2&nbsp;&nbsp;</span>Data Cleaning</a></span></li></ul></li><li><span><a href=\"#Individual-Player-Transfers-Season-2021/2022\" data-toc-modified-id=\"Individual-Player-Transfers-Season-2021/2022-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Individual Player Transfers Season 2021/2022</a></span><ul class=\"toc-item\"><li><span><a href=\"#Web-Scraping\" data-toc-modified-id=\"Web-Scraping-2.1.2.1\"><span class=\"toc-item-num\">2.1.2.1&nbsp;&nbsp;</span>Web Scraping</a></span></li><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-2.1.2.2\"><span class=\"toc-item-num\">2.1.2.2&nbsp;&nbsp;</span>Data Cleaning</a></span></li></ul></li><li><span><a href=\"#Player-Statistics\" data-toc-modified-id=\"Player-Statistics-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Player Statistics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Web-Scraping\" data-toc-modified-id=\"Web-Scraping-2.1.3.1\"><span class=\"toc-item-num\">2.1.3.1&nbsp;&nbsp;</span>Web Scraping</a></span></li><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-2.1.3.2\"><span class=\"toc-item-num\">2.1.3.2&nbsp;&nbsp;</span>Data Cleaning</a></span></li></ul></li></ul></li><li><span><a href=\"#Additional-Data:-GDP-Growth-Data-from-Eurostat\" data-toc-modified-id=\"Additional-Data:-GDP-Growth-Data-from-Eurostat-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Additional Data: GDP-Growth Data from Eurostat</a></span></li></ul></li><li><span><a href=\"#Analysis\" data-toc-modified-id=\"Analysis-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transfermarket-Evolution\" data-toc-modified-id=\"Transfermarket-Evolution-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Transfermarket Evolution</a></span><ul class=\"toc-item\"><li><span><a href=\"#Expenditure-Evolution\" data-toc-modified-id=\"Expenditure-Evolution-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Expenditure Evolution</a></span></li><li><span><a href=\"#Effect-of-Covid-19-Pandemic\" data-toc-modified-id=\"Effect-of-Covid-19-Pandemic-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Effect of Covid-19 Pandemic</a></span></li><li><span><a href=\"#Does-economic-growth-in-a-country-affect-how-much-spendings-grow-on-the-football-transfermarket-in-a-country?\" data-toc-modified-id=\"Does-economic-growth-in-a-country-affect-how-much-spendings-grow-on-the-football-transfermarket-in-a-country?-3.1.3\"><span class=\"toc-item-num\">3.1.3&nbsp;&nbsp;</span>Does economic growth in a country affect how much spendings grow on the football transfermarket in a country?</a></span></li></ul></li><li><span><a href=\"#Player-Performance-&amp;-Price\" data-toc-modified-id=\"Player-Performance-&amp;-Price-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Player Performance &amp; Price</a></span></li><li><span><a href=\"#Is-there-a-Premium-for-English-Players?\" data-toc-modified-id=\"Is-there-a-Premium-for-English-Players?-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Is there a Premium for English Players?</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc7a03",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this project, the goal is to analyse questions about the football transfermarket based on data from the website [transfermarkt.ch](https://www.transfermarkt.ch/). Since there is no way to download the needed data directly from the website, a webscraper will be built that will efficently download all the data needed from the website.\n",
    "\n",
    "This project is structured in the following way. In the [next section](#Getting-and-Cleaning-the-Data), we will first get the different dataframes we need using the `requests` and `BeautifulSoup` libraries. Second, we will clean the different dataframes so we can analyse them. In the [final section](#Analysis) we will try to anwser different football transfer related questions using the data we have scraped.\n",
    "# Getting and Cleaning the Data\n",
    "**Transfermarkt** is a German-based website owned by Axel Springer SE that has footballing information, such as scores, results, statistics, transfer news, and fixtures (Source: [Wikipedia](https://en.wikipedia.org/wiki/Transfermarkt)). The website has extensive transfer and player statistics. However, the data cannot be easily downloaded, which is why it is necessary to build a webscraper to obtain the data. First, we will introduce the `requests` and `BeautifulSoup` libraries needed to scrape the data. After that, we will obtain and clean the data.\n",
    "## Webscraping data from Transfermarkt.ch\n",
    "The Webscraper was built using the tutorial on [fcpython.com](https://fcpython.com/blog/introduction-scraping-data-transfermarkt). What we have on the transfermarkt website is a table like the one below, which displays the 25 teams that have spent the most money on new players since 2010. ![alternative text](Images\\Transfermarkt_Screenshot.png)Our goal is to get such data into a `pandas` dataframe. In order to understand what the websraper does, we need to understand how the data is stored on the website. The data on the website is stored in the HTML-Code underlying this website (see picture below). Now, what we first do is get the relevant code from the website using the `requests` library. Secondly, we will parse the website code into html using the `BeautifulSoup` library. We will then be able to search through this for the data that we want to extract. ![alternative text](Images\\HTML_Screenshot.png)We will now import the packages we need to do the webscraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fac71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b182e2",
   "metadata": {},
   "source": [
    "In the next subsections, we will get three different different dataframes from transfermarkt.ch. We will clean each dataframe right after obtaining the data from the website.\n",
    "### Aggregate Transfer Data (League / Country Level)\n",
    "#### Web-Scraping\n",
    "In this subsection, we will get transfer data on a league level since the year 2000. This means that our goal is to have a table that shows how much each league has collectively spent every year since the year 2000. The table we are trying to get can be found [here](https://www.transfermarkt.ch/transfers/transfersalden/statistik/plus/0?sa=&saison_id=2022&saison_id_bis=2022&land_id=&nat=&pos=&w_s). Please note that the table is stored under a different link for each year. As such, we will need to use a for-loop to get the link for all the years we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a698fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list for years we look at\n",
    "years=[]\n",
    "#for loop to get all years\n",
    "for i in range(2000,2023):\n",
    "    #add individual years to list and turn int to string so we can use it in the link\n",
    "    years.append(str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b3bca6",
   "metadata": {},
   "source": [
    "Now we will do the webscrapintg. To prepare this, we will first create four empty lists, where we will store the data we need for each year: The name of the league and total expenditure.\n",
    "\n",
    "After, we are going to iterate through the link for each year using a for-loop. What we are first going to do in the for-loop is create a variable called ‘headers’ and assign it a string that will tell the website that we are a browser, and not a scraping tool. In short, we’ll be blocked if we are thought to be scraping.\n",
    "\n",
    "Next, we have three lines. The first one assigns the address that we want to scrape to a variable called ‘page’.\n",
    "\n",
    "The second uses the requests library to grab the code of the page and assign it to ‘pageTree’. We use our headers variable here to inform the site that we are pretending to be a human browser.\n",
    "\n",
    "The third, the BeautifulSoup module, parses the website code into html. We will then be able to search through this for the data that we want to extract. This is saved to ‘pageSoup’.\n",
    "\n",
    "Finally, we will add the relevant parts of the HTML code into the respective lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f195b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Empty Lists\n",
    "Leagues=[]\n",
    "Expenditures=[]\n",
    "\n",
    "#iterate through each year of interest\n",
    "for year in years:\n",
    "    #This is used so transfermarkt thinks we are a webbrowser and not a scrapper\n",
    "    headers = {'User-Agent': \n",
    "               'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "    #webpage\n",
    "    page = \"https://www.transfermarkt.ch/transfers/transfersalden/statistik/plus/0?sa=&saison_id=\"+year+\"&saison_id_bis=\"+year+\"&land_id=&nat=&pos=&w_s=\"\n",
    "    #grabs the code of the page\n",
    "    pageTree = requests.get(page, headers=headers)\n",
    "    #parses the website code into html\n",
    "    pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "    \n",
    "    #adds the relevant part of the html code into the respective list\n",
    "    Leagues.append(pageSoup.find_all(\"td\", {\"class\": \"hauptlink no-border-links\"}))\n",
    "    Expenditures.append(pageSoup.find_all(\"td\", {\"class\": \"rechts hauptlink redtext\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b582583e",
   "metadata": {},
   "source": [
    "To get a better idea of how the data stored in the list looks, it makes sense to print one list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Expenditures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d5dc5",
   "metadata": {},
   "source": [
    "We can now go to the next step of turning the data in the list into dataframes we can analyse, i.e. we can now clean the data.\n",
    "#### Data Cleaning\n",
    "In essence, we have two different variables of interest for the time period 2000-2022. The two variables are the two lists we have created in the Webscraping. These lists contain further lists, namely one for each period. To get this data in a format we can work with, we need to do the following steps.\n",
    "\n",
    "1. Clean the two \"lists of lists\", i.e. turn their contents into the data format we need\n",
    "2. Create a dateframe with the the league and Expenditure for each year\n",
    "3. Merge all dataframes together so we will only have one dataframe with the expenditures for the leagues over the years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873eda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the League names from the HTML code\n",
    "\n",
    "#Create empty list to store the league names for every year in a list\n",
    "lig_list=[]\n",
    "#iterate through all years to get the leagues in every year\n",
    "for i in range(len(years)):\n",
    "    #Create Empty list to temporarly store all the leagues (in the correct order) of that year\n",
    "    Ligas=[]\n",
    "    # Iterate through every list in the Leagues list and get all League names for that year\n",
    "    for n in range(len(Leagues[i])):\n",
    "        #make the league name in the right format\n",
    "        Ligas.append(Leagues[i][n].text.replace('\\xa0', '')[:-1])\n",
    "    #use exec function to change the name of the list for that particular year\n",
    "    exec(f\"liga_{years[i]}=Ligas\")\n",
    "    #add the list of that year into the list of lists\n",
    "    exec(f\"lig_list.append(liga_{years[i]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377459cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function that turns the expenditures from string format into an integer\n",
    "\n",
    "def str_to_int(html_list):\n",
    "    #create empty list to store list for every year\n",
    "    int_list=[]\n",
    "    #iterate through all years\n",
    "    for i in range(len(years)):\n",
    "        #create empty list to store values for each year\n",
    "        exp=[]\n",
    "        #iterate through all values in a year and store them (i.e. their string) in exp list\n",
    "        for n in range(len(html_list[i])):\n",
    "            exp.append(html_list[i][n].text)\n",
    "        #create New List to store numbers in integer format\n",
    "        New_List=[]\n",
    "        #iterate through the values in the list, which are in string format, and transform them to integer format\n",
    "        for e in exp:\n",
    "            if \"Mrd\" in e:\n",
    "                e=e.replace(' Mrd. €', '')\n",
    "                e=e.replace(',', '.')\n",
    "                New_List.append(int(float(e)*1000000000))\n",
    "            elif \"Mio\" in e:\n",
    "                e=e.replace(' Mio. €', '')\n",
    "                e=e.replace(',', '.')\n",
    "                New_List.append(int(float(e)*1000000))\n",
    "            elif \"Tsd\" in e:\n",
    "                e=e.replace(' Tsd. €', '')\n",
    "                e=e.replace(',', '.')\n",
    "                New_List.append(int(float(e)*1000))\n",
    "        #use exec function to change the name of the list for that particular year\n",
    "        exec(f\"aux_{years[i]}=New_List\")\n",
    "        # Save list into list of lists\n",
    "        exec(f\"int_list.append(aux_{years[i]})\")\n",
    "    return int_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39196bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply function to expenditures\n",
    "exp_list=str_to_int(Expenditures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e6c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataframe for expenditures for each year\n",
    "\n",
    "#Iterate through all years\n",
    "for i in range(len(years)):\n",
    "    #Create the dataframe out of the lists for that year\n",
    "    df=pd.DataFrame({\"League\":lig_list[i],years[i]:exp_list[i]})\n",
    "    #set the league names as index\n",
    "    df.set_index(\"League\",inplace=True)\n",
    "    #save the df for that year\n",
    "    exec(f\"df_{years[i]}=df\")\n",
    "    #if the same league appears twice, drop it\n",
    "    exec(f\"df_{years[i]} = df_{years[i]}[~df_{years[i]}.index.duplicated(keep='first')]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a14ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create one dataframe out of all dataframes\n",
    "\n",
    "#for loop to go through dataframe of every year\n",
    "for i in range(len(years)-1):\n",
    "    #dataframe after dataframe, merge the dataframe of all years, until you merged all dataframes\n",
    "    exec(f\"df_{years[i+1]}=pd.merge(df_{years[i]},df_{years[i+1]},how='inner',left_index=True,right_index=True)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6a844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how df looks\n",
    "df_2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1584e",
   "metadata": {},
   "source": [
    "Since we are mainly interested in the Top 5 Leagues (i.e. the leagues of England, Spain, Germany, Italy, France), we will only keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ebaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep columns with the league names of top 5 leagues\n",
    "top_5_exp=df_2022.loc[[\"Serie A\",\"Premier League\",\"LaLiga\",\"Ligue 1\",\"Bundesliga\"]]\n",
    "\n",
    "#change the format of the years\n",
    "top_5_exp.columns=pd.period_range(start=list(top_5_exp.columns)[0], end=list(top_5_exp.columns)[-1], freq=\"A\")\n",
    "\n",
    "top_5_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30a7a8",
   "metadata": {},
   "source": [
    "### Individual Player Transfers Season 2021/2022\n",
    "#### Web Scraping\n",
    "We now want to get the individual player transfers from the Season 2021/2022. The table we are trying to get can be found [here](https://www.transfermarkt.ch/transfers/saisontransfers/statistik/top/saison_id/2021/transferfenster/alle/land_id//ausrichtung//spielerposition_id//altersklasse//leihe//plus/1/galerie/0/page/). Since each page only shows the data for 25 players, we will need to iterate through all pages (there are 80). We can now do the webscraping to get all the relevant data about individual player transfers that happened in the 2021/22 Season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list with all page numbers to iterate through\n",
    "all_pages=list(range(1,81))\n",
    "\n",
    "#Create empty lists to store webscraping data for dataframe later\n",
    "Basics=[]\n",
    "age=[]\n",
    "\n",
    "#iterate through every page and get the relevant data\n",
    "for i in all_pages:\n",
    "\n",
    "    #webpage\n",
    "    page = \"https://www.transfermarkt.ch/transfers/saisontransfers/statistik/top/saison_id/2021/transferfenster/alle/land_id//ausrichtung//spielerposition_id//altersklasse//leihe//plus/1/galerie/0/page/\"+str(i)\n",
    "    #grabs the code of the page\n",
    "    pageTree = requests.get(page, headers=headers)\n",
    "    #parses the website code into html\n",
    "    pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "    \n",
    "    #get transfer fee, name, and clubs involved in transfer\n",
    "    Basics.append(pageSoup.find_all(\"td\", {\"class\": \"hauptlink\"}))\n",
    "    #get age of player\n",
    "    age.append(pageSoup.find_all(\"td\", {\"class\":\"zentriert\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a649eb",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "Now that we have the html code, we can get the data we need for the Analysis. We will now first prepare lists where all the data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7fc8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at the first Values\n",
    "Basics[0][0].text\n",
    "age[0][1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since every 4th item on web page is a new player, we create a list with every 4th item\n",
    "lst=list(range(len(Basics)))\n",
    "lst[0::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bef4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that cleanes the name list\n",
    "def name_cleaner(lst):\n",
    "    #Create auxillary list\n",
    "    aux_list=[]\n",
    "    #Go through Names list and replace the \"\\n\" in the beginning and empty space in end\n",
    "    for i in lst: \n",
    "        i=i[:-1]\n",
    "        aux_list.append(i.replace(\"\\n\",\"\"))\n",
    "    return aux_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0eb1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create List of Names\n",
    "Names=[]\n",
    "#for loop to go through all pages\n",
    "for page in range(len(Basics)):\n",
    "    lst=list(range(len(Basics[page])))\n",
    "    for i in lst[0::4]:\n",
    "        #This is done to replace all the uncessary stuff from the Name\n",
    "        Names.append(Basics[page][i].text)\n",
    "#\"Clean\" Names\n",
    "Names=name_cleaner(Names)\n",
    "Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c44cd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create List of Selling clubs\n",
    "Left=[]\n",
    "\n",
    "#iterate through all pages\n",
    "for page in range(len(Basics)):\n",
    "    #iterate through whole page\n",
    "    lst=list(range(len(Basics[page])))\n",
    "    #Every 4th item new selling club\n",
    "    for i in lst[1::4]:\n",
    "        #Get selling club\n",
    "        Left.append(Basics[page][i].text) \n",
    "#\"Clean\" Names        \n",
    "Left=name_cleaner(Left)\n",
    "Left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df23b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create List of Buying clubs\n",
    "Joined=[]\n",
    "\n",
    "#iterate through all pages\n",
    "for page in range(len(Basics)):\n",
    "    #iterate through whole page\n",
    "    lst=list(range(len(Basics[page])))\n",
    "    #Every 4th item new selling club\n",
    "    for i in lst[2::4]:\n",
    "        #Get selling club\n",
    "        Joined.append(Basics[page][i].text) \n",
    "#\"Clean\" Names\n",
    "Joined=name_cleaner(Joined)\n",
    "Joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create List of transfer fee\n",
    "Fee=[]\n",
    "\n",
    "#iterate through all pages\n",
    "for page in range(len(Basics)):\n",
    "    lst=list(range(len(Basics[page])))\n",
    "    #starting from the thrid value, get every 4th value on the page (i.e all transfer fees)\n",
    "    for i in lst[3::4]:\n",
    "        #Get transfer fee\n",
    "        Fee.append(Basics[page][i].text) \n",
    "Fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5fceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list with ages\n",
    "age_list=[]\n",
    "\n",
    "#iterate through all pages\n",
    "for page in range(len(age)):\n",
    "    lst=list(range(len(age[page])))\n",
    "    #starting from the first value, get every 4th value on the page (i.e all ages)\n",
    "    for i in lst[1::4]:\n",
    "        #get age\n",
    "        age_list.append(int(age[page][i].text)) \n",
    "age_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204da325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library needed later\n",
    "import re\n",
    "#Get player ID on transfermarkt.ch. This is done so we can get player statistics late\n",
    "ID=[]\n",
    "\n",
    "#iterate through all pages\n",
    "for page in range(len(Basics)):\n",
    "    lst=list(range(len(Basics[page])))\n",
    "    #starting from the 0th value, get every 4th value on the page (i.e all ids)\n",
    "    for i in lst[0::4]:\n",
    "        #get link with player ID\n",
    "        link=Basics[page][i].find(\"a\")[\"href\"]\n",
    "        #remove everything except digits and add to list\n",
    "        #code for removing everyting but digits from string is from here: https://stackoverflow.com/questions/1450897/remove-characters-except-digits-from-string-using-python\n",
    "        ID.append(re.sub('\\D',\"\", link)) \n",
    "ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3325c2c7",
   "metadata": {},
   "source": [
    "Now that we have all the data we need in columns, we can create the transfer fee dataframe and perform the necessary data transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644ed00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Data Frame from the lists\n",
    "transfers = pd.DataFrame({\"Player\":Names,\"ID\":ID,\"Age\":age_list,\"Left\":Left,\"Joined\":Joined,\"Fee\":Fee})\n",
    "transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921505e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list with True for all players that were loaned or left the club for free, since these data points are irrelevant for our analysis\n",
    "\n",
    "#empty list\n",
    "Loans=[]\n",
    "\n",
    "#iterate through all transfer fees\n",
    "for i in transfers.Fee:\n",
    "     #since all instances we don't need have a \"e\" in them (and only those instances), we get those items\n",
    "    Loans.append(\"e\" in i) \n",
    "Loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5089d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get indices and drop player names from datafram\n",
    "indexNames = transfers[Loans].index\n",
    "transfers.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since transfer fees are strings, we need to transform them to integer type strings into int and create new list with integers\n",
    "New_List=[]\n",
    "for i in transfers.Fee:\n",
    "    if \"Mrd\" in i:\n",
    "        i=i.replace(' Mrd. €', '')\n",
    "        i=i.replace(',', '.')\n",
    "        New_List.append(int(float(i)*1000000000))\n",
    "    elif \"Mio\" in i:\n",
    "        i=i.replace(' Mio. €', '')\n",
    "        i=i.replace(',', '.')\n",
    "        New_List.append(int(float(i)*1000000))\n",
    "    elif \"Tsd\" in i:\n",
    "        i=i.replace(' Tsd. €', '')\n",
    "        i=i.replace(',', '.')\n",
    "        New_List.append(int(float(i)*1000))\n",
    "    else:\n",
    "        New_List.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdaa93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop old transfer fees that are strings\n",
    "transfers.drop(\"Fee\", axis = 1, inplace = True)\n",
    "\n",
    "# Add inteeger transfer fees\n",
    "transfers[\"Fee\"] = New_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all np.nan\n",
    "transfers.dropna(inplace=True)\n",
    "\n",
    "#get all duplicate entries (If player changed club more than once in a season)\n",
    "a=transfers[transfers.ID.duplicated()]\n",
    "\n",
    "#Get list with all indicices of duplicate entries\n",
    "duplicates=[]\n",
    "for i in range(a.shape[0]):\n",
    "    duplicates.append(transfers.where(transfers[\"ID\"]==a.iloc[i][\"ID\"]).dropna().index)\n",
    "\n",
    "#go through all plyers that are in dataframe twice (cause they were bought and resold in same transfer window)\n",
    "for i in duplicates:\n",
    "    transfers.drop(transfers.loc[i][\"Fee\"].idxmin(), axis=0,inplace=True)#drop lower transferfee\n",
    "    \n",
    "#drop all duplicates in transfers\n",
    "transfers.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd80731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set player name as index and drop name column\n",
    "transfers.index=transfers[\"Player\"]\n",
    "transfers.drop(\"Player\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab67f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd775f52",
   "metadata": {},
   "source": [
    "We have now finished to clean the data and have received a dataframe with all the players who joined a new club for a transfer fee in the 2021/22 Season.\n",
    "### Player Statistics\n",
    "For our analysis we will also need some basic player statistics (e.g. Games Played, Goals Scored, Goals Assissted, etc.) for all players who were involved in a transfer in the 2021/22 season. We get the statistics for the season just before the player was transfered (i.e. the 2020/21 season). An example of the table we need can be found [here](https://www.transfermarkt.co.uk/Jack-Grealish/leistungsdatendetails/spieler/203460/saison/2020/verein/0/liga/0/wettbewerb//pos/0/trainer_id/0/plus/1).\n",
    "\n",
    "Before we can scrape the data for every player, we need to make some preperations. In particular, we need to prepare the link for every player. For every player, there are two unique features in the link:\n",
    "1. The Players Name\n",
    "2. A unique Transfermarkt Player-ID\n",
    "\n",
    "We have both features saved in the \"transfers\" table, which is why we can now easily access the information for every player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6a48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get player names and ids for which we need data\n",
    "players=list(transfers.index)\n",
    "ids=list(transfers.ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjsut player name so it can be used for the url\n",
    "\n",
    "#create empty list to store url\n",
    "players_url=[]\n",
    "#iterate through all players and make necessary adjustments\n",
    "for name in players:\n",
    "    name=name.replace(\"'\",\"\")\n",
    "    name=name.replace(\".\",\"\")\n",
    "    #add url to list\n",
    "    players_url.append(name.replace(\" \",\"-\"))\n",
    "players_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76818b8f",
   "metadata": {},
   "source": [
    "#### Web Scraping\n",
    "Now that that the Urls are prepared, we can do the webscraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty lists to store data/theml code\n",
    "stats=[]\n",
    "total=[]\n",
    "heights=[]\n",
    "\n",
    "\n",
    "#iterate through all players\n",
    "for i in range(len(ids)):\n",
    "    #webpage\n",
    "    page=\"https://www.transfermarkt.co.uk/\"+players_url[i]+\"/leistungsdatendetails/spieler/\"+ids[i]+\"/saison/2020/verein/0/liga/0/wettbewerb//pos/0/trainer_id/0/plus/1\"\n",
    "    #grab the code of the page and assign it to ‘pageTree‘\n",
    "    pageTree = requests.get(page, headers=headers)\n",
    "    #parses the website code into html\n",
    "    pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "    #‘find_all’ function to look for the tags in the page\n",
    "    stats.append(pageSoup.find_all(\"td\", {\"class\": \"zentriert\"}))\n",
    "    total.append(pageSoup.find_all(\"td\", {\"class\": \"rechts\"}))\n",
    "    heights.append(pageSoup.find_all(\"span\",{\"class\":\"data-header__content\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717f55db",
   "metadata": {},
   "source": [
    "#### Data Cleaning\n",
    "Now that we have the html code, we can get the data we need for the Analysis from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funtion to converse the data to numeric\n",
    "def str_conv(lst):\n",
    "    #create empty list\n",
    "    new_list=[]\n",
    "    #iterate through list with statistic\n",
    "    for item in lst:\n",
    "        #check if there is a dash --> Turn to a 0\n",
    "        if item == \"-\":\n",
    "            new_list.append(0)\n",
    "        #if item is not 0, it is a number --> turn to float  \n",
    "        else:\n",
    "            try:\n",
    "                new_list.append(float(item))\n",
    "            #If it's not 0 or a float, put in nan\n",
    "            except ValueError:\n",
    "                new_list.append(np.nan)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to do the list transformation so I can work with the data\n",
    "\n",
    "#function takes as input the html code and where in the html code you can find the data point\n",
    "def list_transform(webdata,index):\n",
    "    #empty list\n",
    "    lst=[]\n",
    "    #itereate through all pages/players\n",
    "    for i in range(len(webdata)):\n",
    "        #If empty (i.e. no stats)--> np.nan\n",
    "        if webdata[i]==[]:\n",
    "            lst.append(np.nan)\n",
    "        else:\n",
    "            #checks which part of the html code is given into the function and makes the appropriate transformation\n",
    "            if webdata==total:\n",
    "                #remove \"'\" from numbers\n",
    "                number=webdata[i][index].text.replace(\"'\",\"\")\n",
    "                lst.append(number.replace(\".\",\"\"))\n",
    "            elif webdata==heights:\n",
    "                #remove \"'\" from numbers\n",
    "                number=webdata[i][index].text.replace(\",\",\"\")\n",
    "                lst.append(number.replace(\" m\",\"\"))#remove \" m\" from height\n",
    "            else:\n",
    "                lst.append(webdata[i][index].text)\n",
    "    #apply sting conversion function created before\n",
    "    lst=str_conv(lst)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdd01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the functions cretead to transform the data into a format we can work with and put it in a list\n",
    "\n",
    "#how many times player was in squad\n",
    "squad=list_transform(stats,0)\n",
    "#how many games a player has actively played in\n",
    "games_played=list_transform(stats,1)\n",
    "#how many points a player has won per game he has played in\n",
    "PPG=list_transform(stats,2)\n",
    "#how many goals a player has scored\n",
    "goals=list_transform(stats,3)\n",
    "#how many goals a player has assisted\n",
    "assists=list_transform(stats,4)\n",
    "# How many owngoals a player has scored\n",
    "own_goals=list_transform(stats,5)\n",
    "#how many times a player has been subbed on\n",
    "sub_on=list_transform(stats,6)\n",
    "#how many times a player has been subbed off\n",
    "sub_off=list_transform(stats,7)\n",
    "#how many yellow cards a player has gotten\n",
    "yellow_cards=list_transform(stats,8)\n",
    "#how many red cards a player has gotten\n",
    "red_cards=list_transform(stats,9)\n",
    "#how many times a player has gotten two yellow cards in one game\n",
    "two_yellows=list_transform(stats,10)\n",
    "#how many penalties a player has scored\n",
    "penalty_goals=list_transform(stats,11)\n",
    "#how many minutes a player has played (only the case if player is field player)\n",
    "minutes_field=list_transform(total,2)\n",
    "#how many minutes a player has played (only the case if player is Goalkeeper)\n",
    "minutes_GK=list_transform(total,1)\n",
    "#get height of player\n",
    "height=list_transform(heights,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ca47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get position of player\n",
    "positions=[]\n",
    "#for loop to go through all pagers/player\n",
    "for i in range(len(heights)):\n",
    "    #check if there is a value for position\n",
    "    try:\n",
    "        #make necessary adjsustment to string\n",
    "        position=heights[i][7].text[9:].replace(\" \",\"\")\n",
    "        positions.append(position)\n",
    "    #if no value for position, just add NAN\n",
    "    except IndexError:\n",
    "        positions.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cfb751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get nationality of player\n",
    "nationality=[]\n",
    "#for loop to go through all pagers/player\n",
    "for i in range(len(heights)):\n",
    "    #check if there is a value for Nationality\n",
    "    try:\n",
    "        #make necessary adjsustment to string\n",
    "        nation=heights[i][5].text[9:].replace(\" \",\"\")\n",
    "        nationality.append(nation)\n",
    "    #if no value for position, just add NAN\n",
    "    except IndexError:\n",
    "        nationality.append(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe and drop rows where data missing\n",
    "statistics = pd.DataFrame({\"Player\":players,\"ID\":ids,\"Nationality\":nationality,\"Position\":positions,\"Height (cm)\":height,\"Games in Squad\":squad,\"Games Played\":games_played,\"Points per game\":PPG,\"Goals\":goals,\"Assists\":assists,\"Own goals\":own_goals,\"Games subbed on\":sub_on, \"Games subbed off\":sub_off,\"Yellow Cards\":yellow_cards,\"Red Cards\":red_cards,\"Two Yellow Cards\":two_yellows,\"Penalty Goals\":penalty_goals,\"Minutes Field\":minutes_field,\"Minutes GK\":minutes_GK})\n",
    "#drop all rows which have data missing\n",
    "statistics.dropna(inplace=True)\n",
    "#Set player name as index\n",
    "statistics.index=statistics[\"Player\"]\n",
    "#drop player column\n",
    "statistics.drop(\"Player\", axis=1, inplace=True)\n",
    "#If goalkeeper --> 1, else-->0\n",
    "statistics[\"Position\"]=statistics[\"Position\"]==\"Goalkeeper\"\n",
    "statistics[\"Position\"]=statistics[\"Position\"].astype(int)\n",
    "#rename column\n",
    "statistics.rename(columns={'Position': 'Position (GK: 1, Other: 0)'},inplace=True)\n",
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Goal: get one column with minutes played (in the moment we have seperate for field players and seperate for Goal Keeper)\n",
    "\n",
    "#Create empty coulumn in DataFrame\n",
    "statistics[\"Minutes\"]=np.nan\n",
    "#iterate through all rows to check wheter player is GK or not\n",
    "for index,row in statistics.iterrows():\n",
    "    #if he's not a GK, take the values from the Minutes Field Column\n",
    "    if statistics[\"Position (GK: 1, Other: 0)\"][index]==0:\n",
    "        statistics[\"Minutes\"][index]=statistics[\"Minutes Field\"][index]\n",
    "    #if he is a GK, take the value from the Minutes GK column\n",
    "    elif statistics[\"Position (GK: 1, Other: 0)\"][index]==1:\n",
    "        statistics[\"Minutes\"][index]=statistics[\"Minutes GK\"][index]\n",
    "\n",
    "#drop columns that are not needed now        \n",
    "statistics.drop([\"Minutes Field\",\"Minutes GK\"], axis=1, inplace=True)\n",
    "#print df\n",
    "statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a531a",
   "metadata": {},
   "source": [
    "Through Webscraping, we have now created three tables with football statistics. Below is an **overview** of the tables:\n",
    "1. **top_5_exp**: Dataframe that shows the total expenditure on the transfer market in the top 5 leagues for every year since 2000.\n",
    "2. **transfers**: Dataframe which lists all the individual player transfers that happened in the 2021/22 season.\n",
    "3. **statistics**: Dataframe which shows player statistics for all the players that changed clubs in the 2021/22 season in the season prior to their transfer.\n",
    "\n",
    "## Additional Data: GDP-Growth Data from Eurostat\n",
    "For our analysis, we will also need GDP growth rates.The statistical office of the European Union offers the access of a data base through the REST API. One python package that enables to access this interface is the [`eurostat`](https://pypi.org/project/eurostat/) library. Its website provides useful documentation of the functionalities of the package.For this project, we will need to use the `get_data_df` method.\n",
    "\n",
    "The `get_data_df` method gets datasets from the Eurostat database by specifying the filenames ('tec00115' for the real GDP growth rates). As Eurostat flags missing values with a colon, we can pass the argument `flags=False` to replace those values with a `np.nan` object. The function returns the corresponding datasets as `pd.DataFrame`, which we will store as `gdp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install eurostat #run the code on the left if you don't have the package installed\n",
    "import eurostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038aa24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Data from Eurostat api\n",
    "gdp = eurostat.get_data_df('tec00115', flags=False)    # Real GDP growth rates\n",
    "gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f6f88",
   "metadata": {},
   "source": [
    "For our analysis we need the GDP-Growth for each country. For this, we firstly need to only keep the rows that have the unit *CLV_PCH_PRE*, which means only the values which show the percentage change from last year. We then transform the dataframe and only keep the growth rates for the countries for which we need them, namely England, Spain, Germany, Italy, and France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dcb86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the rows with the right unit (percentage change from last year)\n",
    "gdp = gdp[gdp['unit']=='CLV_PCH_PRE']\n",
    "\n",
    "#rename column to country\n",
    "gdp.rename(columns={'geo\\\\TIME_PERIOD':'country'}, inplace=True)\n",
    "\n",
    "# Drop the unneeded column of unit and na_item\n",
    "gdp = gdp.drop(columns=['unit', 'na_item','freq'])\n",
    "\n",
    "# Set the country names as index\n",
    "gdp = gdp.set_index(\"country\")\n",
    "\n",
    "#only keep five countries of interest\n",
    "gdp=gdp.loc[[\"UK\",\"DE\",\"ES\",\"FR\",\"IT\"]]\n",
    "\n",
    "# Create variable \"period\" with the timeperiods \n",
    "period = pd.period_range(start=gdp.columns[0],end=gdp.columns[-1], freq='A', name='Annual Frequency')\n",
    "gdp.columns=period\n",
    "\n",
    "#Divide everyting through 100 so we will have percentages\n",
    "gdp=gdp/100\n",
    "\n",
    "gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b0bfa",
   "metadata": {},
   "source": [
    "Finally, we have gotten all the data we need and can start with the analysis of our questions.\n",
    "# Analysis\n",
    "In our analyis, we will want to look at the following three topics:\n",
    "1. How has the transfermarket evolved in the last couple of years?\n",
    "2. Does Player Performance lead to higher prices for that player?\n",
    "3. Is there really a premium for English football players (For reference: See [this article](https://daniel-okunola6.medium.com/why-english-footballers-are-so-expensive-c94a8b768b78))\n",
    "\n",
    "We will anwser the different questions graphically and/or statistically with a linear regression. To create graphs, we will use the `matplotlib` library. For the statistical analysis, we will use the [`statsmodels`](https://www.statsmodels.org/stable/index.html) library, which is designed for more statistically-oriented approaches to data analysis, with an emphasis on econometric analyses.\n",
    "\n",
    "We will now import all needed packages for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c894677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf6c410",
   "metadata": {},
   "source": [
    "## Transfermarket Evolution\n",
    "For this topic, we will anwser three questions:\n",
    "1. How have transfermarket expenditures developed in the top 5 leagues since the year 2000? *(Will be awnsered graphically)*\n",
    "2. What was the effect of the Covid-19 pandemic on transfermarket expenditures in the top 5 leagues? *(Will be awnsered graphically)*\n",
    "3. For the top 5 leagues, how is GDP-growth in the country related to growth in transfermarket expenditures?*(Will be awnsered statistically)*\n",
    "\n",
    "### Expenditure Evolution\n",
    "To check this, we will create a line chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e9519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifies the defult size of plots [6.0,4.0] inches\n",
    "matplotlib.rcParams['figure.figsize'] = [12.0,6.0]\n",
    "#transposes the data and plots it\n",
    "top_5_exp.T.plot(figsize=(20,10))\n",
    "#Set Label of y_axis\n",
    "plt.ylabel(\"Expenditures (in Billions of €)\",size=20)\n",
    "#make the plot have a grid\n",
    "plt.grid()\n",
    "#set the title of the plot\n",
    "plt.title(\"Transfer Expenditures in the top 5 Leagues between 2000-2022\", size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14aa6ba",
   "metadata": {},
   "source": [
    "As we can see, the expenditures on the transfermarket have risen strongly since the year 2000. Espacially in the English Premier League the values seem to have risen very strongly. However, there seems to have been a decline since the Covid-19 Pandemic. Let's look at it a bit closer.\n",
    "### Effect of Covid-19 Pandemic\n",
    "To see the effect of the Pandemic and expenditures in the trasnfermarket, we will colour the period where the pandemic had its strongest effect on the economy (i.e. 2020-2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ce46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modifies the defult size of plots [6.0,4.0] inches\n",
    "matplotlib.rcParams['figure.figsize'] = [12.0,6.0]\n",
    "#transposes the data and plots it\n",
    "top_5_exp.T.plot(figsize=(20,10))\n",
    "#Set Label of y_axis\n",
    "plt.ylabel(\"Expenditures (in Billions of €)\",size=20)\n",
    "#make the plot have a grid\n",
    "plt.grid()\n",
    "#set the title of the plot\n",
    "plt.title(\"Transfer Expenditures in the top 5 Leagues between 2000-2022\", size=30)\n",
    "#Colour period of the pandemic\n",
    "plt.axvspan(\"2019\", \"2021\", color='grey', alpha=0.2, lw=1,label=\"COVID-19 (2020Q2-2020Q4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d26573",
   "metadata": {},
   "source": [
    "As we can see in the graph above, the pandemic seems to have significantly reduced the transfermaket expenditures for most of the top-5 leagues. Espacially the Spanish La Liga and the Italian Serie A, two of the countries which were worse affected by the pandemic, have spend significantly less money on the transfermarket since the pandemic started. In contrast, the English Premier League has only reduced transfer spending by relatively little during the pandemic. Even more so, the Premier League is the only top-5 league in which the transfer expenditures have recovered (and even surpassed) the pre-pandemic highs. As such, the pandemic seems to have had no lasting effect on the English Premier League, while the effects can still be felt for the other four top-5 leagues.\n",
    "### Does economic growth in a country affect how much spendings grow on the football transfermarket in a country?\n",
    "To analyse this question, we will first need to adapt our top_5_exp dataset to show growth rates instead of absolute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfebd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate growth rates\n",
    "top_5_exp_g=top_5_exp.pct_change(axis=\"columns\")\n",
    "top_5_exp_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4334d4",
   "metadata": {},
   "source": [
    "We will now have to combine the expenditure growth Dataframe with the GDP growht dataframe. Since we will need to run one regression for each country, we will need to create one dataframe for each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56868783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the expenditure indexes to match the GDP indexes\n",
    "top_5_exp_g.index=[\"IT\",\"UK\",\"ES\",\"FR\",\"DE\"]\n",
    "top_5_exp_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b4169",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dictionary that stores the dataframe for each country\n",
    "\n",
    "#create empty dictionary\n",
    "df_dict={}\n",
    "#iterate through all countries\n",
    "for index, row in top_5_exp_g.iterrows():\n",
    "    #For country \"index\", get the growth rates and transform them into a dataframe instead of an array\n",
    "    df1=pd.DataFrame(top_5_exp_g.loc[index])\n",
    "    df2=pd.DataFrame(gdp.loc[index])\n",
    "    #merge the dataframes and name them according to the country\n",
    "    exec(f\"df_{index}=pd.merge(df1,df2,how='inner',left_index=True,right_index=True)\")\n",
    "    #rename columns\n",
    "    exec(f\"df_{index}.columns=['Transfer_Growth','GDP_Growth']\")\n",
    "    #save df into dictionary\n",
    "    exec(f\"df_dict['{index}']=df_{index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096915a",
   "metadata": {},
   "source": [
    "With this, we can now run the regression using the [`statsmodels`](https://www.statsmodels.org/stable/index.html) library. Conducting an OLS regression with the statsmodels package is very easy. We first need to create a dataframe **Y** for the dependent variable and a dataframe **X** for the independent variable. Additionally, we will need to add a constant column with ones to the dataframe with the independent variables with the statsmodles method `sm.add_constant`. Otherwise, the regression will be created without an intercept $\\beta_0$ by default. The regression will be initialized by creating and `sm.OLS` object. We then fit the model by calling the OLS object's `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208cf507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dictionary to store regression results for each country\n",
    "regresults_dic = {}\n",
    "\n",
    "# Iterate through all age groups\n",
    "for country in df_dict:\n",
    "\n",
    "  # Defining the dependent variable\n",
    "  y = df_dict[country][\"Transfer_Growth\"]\n",
    "\n",
    "  # Defining the regressors and adding a constant (the intercept b0) with the sm.add_constant method\n",
    "  x = sm.add_constant(df_dict[country]['GDP_Growth'])\n",
    "\n",
    "  # Initializing the OLS rergeression\n",
    "  regression = sm.OLS(y, x, missing='drop')\n",
    "\n",
    "  # Fit the model by calling the OLS object’s fit() method\n",
    "  regresults = regression.fit()\n",
    "\n",
    "  # Save model to dictionary\n",
    "  regresults_dic[country] = regresults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4613bcf",
   "metadata": {},
   "source": [
    "The `statsmodels` library gives many options to analyse the results of the regression. To get an overview of the results, it is advisable to first use the `summary` method, which prints an overview of the regression results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regresults_dic['IT'].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6225c7a8",
   "metadata": {},
   "source": [
    "It is also possible to access different properties of a regression individually. In the following, we will create a dataframe with different properties of the regressions of the different age groups.\n",
    "\n",
    "- With `params` you get a list of the different coefficients $\\beta_i$\n",
    "- With `rsquared` you get the $R^2$\n",
    "- With `rsquared_adj` you get the Adjusted-$R^2$\n",
    "- With `pvalues` you get the different p-values of the coefficients\n",
    "\n",
    "You can access many more properties of a regression. You can get an overview [here](https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.RegressionResults.html#statsmodels.regression.linear_model.RegressionResults)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c23222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dictionary to create the dataframe later on\n",
    "overview_dic = {}\n",
    "\n",
    "# Iterate through all regression results\n",
    "for country in regresults_dic:\n",
    "    # Create dictionary entry for certain country\n",
    "    aux = regresults_dic[country]\n",
    "    # Store list with all values that are of importance into the age_group entry\n",
    "    overview_dic[country] = [aux.params[0], aux.params[1], aux.rsquared, aux.rsquared_adj, aux.pvalues[1]] \n",
    "#Create a dataframe out of the dictionary and transpose the dataframe so we have the agegroup as index\n",
    "overview_df = pd.DataFrame(overview_dic, index=[\"B0\",\"B1\",\"R-Squared\",\"Adjusted R-Squared\",\"p-value\"]).T\n",
    "\n",
    "# Create column that has the value True if B1 if the variable is significant and False if it is not\n",
    "overview_df[\"Significant (p < 0.05)\"] = overview_df[\"p-value\"].map(lambda x: x<0.05)\n",
    "\n",
    "overview_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b196e8e2",
   "metadata": {},
   "source": [
    "As we can see from the table, there seems to be a positive relationship between GDP-Growth and Transfer-Expenditure Growth. However, this relationship seems to be statstically insignificant in most cases. Please note that the results from this regression should be viewed with skeptecism, as the number of observations is very low(n<30). Accordingly, we have also received such a warning message from Python.\n",
    "## Player Performance & Price\n",
    "To analyse this question, we will run an OLS regression, with the players statistics being the independent variable and the transfer-fee being the dependent variable. To run the OLS, we will first need to merge the statistics and the transfers dataframes and drop the columns that are not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge Dataframes. Use \"inner\" method so we will have all values for eache player\n",
    "reg_df=pd.merge(statistics,transfers,how='inner',left_index=True,right_index=True)\n",
    "#we will now drop all column that are not needed for the analysis + the \"Games in Squad\" and \"Games Played\" columns, to deal with multicollinearity\n",
    "reg_df.drop([\"ID_x\",\"Nationality\",\"Games in Squad\",\"Games Played\",\"ID_y\",\"Left\",\"Joined\"],axis=1,inplace=True)\n",
    "#print df\n",
    "reg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b4d13",
   "metadata": {},
   "source": [
    "We can now run the OLS regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the dependent variable\n",
    "y = reg_df[\"Fee\"]\n",
    "\n",
    "# Defining the regressors and adding a constant (the intercept b0) with the sm.add_constant method\n",
    "x=sm.add_constant(reg_df[['Position (GK: 1, Other: 0)','Height (cm)','Points per game','Goals','Assists','Own goals','Games subbed on','Games subbed off',\"Yellow Cards\",\"Red Cards\",\"Penalty Goals\",\"Minutes\",\"Age\"]])\n",
    "\n",
    "# Initializing the OLS rergeression\n",
    "regression = sm.OLS(y, x, missing='drop')\n",
    "\n",
    "# Fit the model by calling the OLS object’s fit() method\n",
    "regresults = regression.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b34fc67",
   "metadata": {},
   "source": [
    "We now print the Regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regresults.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c3c1b",
   "metadata": {},
   "source": [
    "From the regression results, we can see that the player statistics have little explanatory power, as the Adjusted-$R^2$ of the Model is very low. However, there seem to be some significant results. The most economicaly important result, which is also significant, is the Points per Game won in the previous season, which indicate that players that have played for teams which were succesful in the previous Season will be more expensive. Further, a player's height, the number of goals scored in the previous season, and the number of assissts given in the previous season seem to also significantly increase a players value, while a players age seems to significantly decrease a players value. Please note that the Results of the Regression should be taken with caution, as the regression outputs displays a message warning of a potential multicollinearity problem.\n",
    "## Is there a Premium for English Players?\n",
    "When following the transfermarket, it seems that teams always need to pay a premium for players who are British. The goal is now to analyse wheter there indeed is such a premium. For this, we will run an OLS regression, with the independent variable being a dummy variable that equals 1 if a player is British and 0 otherwise. Meanwhile, the dependent Variable is the transfer fee.\n",
    "We will first need to merge and clean the dataframe, similar to the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b293fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge Dataframes. Use \"inner\" method so we will have all values for eache player\n",
    "reg_df=pd.merge(statistics,transfers,how='inner',left_index=True,right_index=True)\n",
    "#we will now drop all columns except the players nationality and fee\n",
    "reg_df=reg_df[[\"Nationality\",\"Fee\"]]\n",
    "#print df\n",
    "reg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8cbd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn nationality into categorial variabals\n",
    "\n",
    "#iterate through all rows\n",
    "for index,row in reg_df.iterrows():\n",
    "    #if nationality is England, assign value 1\n",
    "    if reg_df[\"Nationality\"][index] == \"England\":\n",
    "        reg_df[\"Nationality\"][index]=1\n",
    "    # else, assign Value 0\n",
    "    else:\n",
    "        reg_df[\"Nationality\"][index]=0\n",
    "        \n",
    "#turn Nationality variable into categorial variable\n",
    "reg_df[\"Nationality\"]=reg_df.Nationality.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f8559",
   "metadata": {},
   "source": [
    "Now, we can run the OLS regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the dependent variable\n",
    "y = reg_df[\"Fee\"]\n",
    "\n",
    "# Defining the regressors and adding a constant (the intercept b0) with the sm.add_constant method\n",
    "x=sm.add_constant(reg_df[[\"Nationality\"]])\n",
    "\n",
    "# Initializing the OLS rergeression\n",
    "regression = sm.OLS(y, x, missing='drop')\n",
    "\n",
    "# Fit the model by calling the OLS object’s fit() method\n",
    "regresults = regression.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9d4a6",
   "metadata": {},
   "source": [
    "We can now print the regession results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b320b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regresults.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37071d2a",
   "metadata": {},
   "source": [
    "While the model only explains less than 5% of the variation in Player Price, the fact that a player is English seems to significantly increase the value of a player. The results from this Analysis suggest that a player being English increase his value by around 11.67 million Euros.\n",
    "# Conclusion\n",
    "In Conclusion, we were able to find the following from our analysis:\n",
    "- Transfer Expenditures have been increasing sharply in the top-5 leagues since 2000.\n",
    "- The consequences of the Covid-19 pandemic had a negative and lasting effect on the transfer expenditures of all the top-5 leagues, except the English Premier League.\n",
    "- Economic Growth (as measured by GDP-Growth) has a positive, but statistically insignificant effect on transfer expenditure growth.\n",
    "- Player Performance significantly affects the price of a player.\n",
    "- There is transfer fee premium on players who are British."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "314px",
    "width": "420px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "355.364px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
